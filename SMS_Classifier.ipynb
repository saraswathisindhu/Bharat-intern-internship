{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVTR6PmT4FgV67Boo4MaL4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraswathisindhu/Bharat-intern-internship/blob/main/SMS_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import scipy as sp\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yZxSNUvkDWOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/spam.csv\",encoding='latin-1')"
      ],
      "metadata": {
        "id": "IMbhy-lVFUQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxSoHvYrGeoi",
        "outputId": "630aaacd-acca-4433-9002-03983b1e2101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "Vb0I0ykTGuI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QmScn4GHRjQ",
        "outputId": "ba63385d-5a35-45c1-da35-92ac49a16434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1  \\\n",
            "0  ham    \n",
            "1  ham    \n",
            "2  spam   \n",
            "3  ham    \n",
            "4  ham    \n",
            "\n",
            "                                                                                                                                                            v2  \\\n",
            "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                               \n",
            "1  Ok lar... Joking wif u oni...                                                                                                                                 \n",
            "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
            "3  U dun say so early hor... U c already then say...                                                                                                             \n",
            "4  Nah I don't think he goes to usf, he lives around here though                                                                                                 \n",
            "\n",
            "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
            "0  NaN        NaN        NaN        \n",
            "1  NaN        NaN        NaN        \n",
            "2  NaN        NaN        NaN        \n",
            "3  NaN        NaN        NaN        \n",
            "4  NaN        NaN        NaN        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwGHWtBUG2j7",
        "outputId": "c6a1f9ae-b87a-4a1f-9f7b-a2e5cab54939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        v1  \\\n",
            "0     ham    \n",
            "1     ham    \n",
            "2     spam   \n",
            "3     ham    \n",
            "4     ham    \n",
            "...   ...    \n",
            "5567  spam   \n",
            "5568  ham    \n",
            "5569  ham    \n",
            "5570  ham    \n",
            "5571  ham    \n",
            "\n",
            "                                                                                                                                                                     v2  \\\n",
            "0     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                     \n",
            "1     Ok lar... Joking wif u oni...                                                                                                                                       \n",
            "2     Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's         \n",
            "3     U dun say so early hor... U c already then say...                                                                                                                   \n",
            "4     Nah I don't think he goes to usf, he lives around here though                                                                                                       \n",
            "...                                                             ...                                                                                                       \n",
            "5567  This is the 2nd time we have tried 2 contact u. U have won the å£750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.   \n",
            "5568  Will Ì_ b going to esplanade fr home?                                                                                                                               \n",
            "5569  Pity, * was in mood for that. So...any other suggestions?                                                                                                           \n",
            "5570  The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free                                       \n",
            "5571  Rofl. Its true to its name                                                                                                                                          \n",
            "\n",
            "     Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
            "0     NaN        NaN        NaN        \n",
            "1     NaN        NaN        NaN        \n",
            "2     NaN        NaN        NaN        \n",
            "3     NaN        NaN        NaN        \n",
            "4     NaN        NaN        NaN        \n",
            "...   ...        ...        ...        \n",
            "5567  NaN        NaN        NaN        \n",
            "5568  NaN        NaN        NaN        \n",
            "5569  NaN        NaN        NaN        \n",
            "5570  NaN        NaN        NaN        \n",
            "5571  NaN        NaN        NaN        \n",
            "\n",
            "[5572 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'v1':'label','v2':'Text'})\n",
        "df['label_enc'] = df['label'].map({'ham':0,'spam':1})\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EKBjQwnHikh",
        "outputId": "b3a227c8-f79d-4d38-989e-5a966a8148b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label  \\\n",
            "0  ham    \n",
            "1  ham    \n",
            "2  spam   \n",
            "3  ham    \n",
            "4  ham    \n",
            "\n",
            "                                                                                                                                                          Text  \\\n",
            "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                               \n",
            "1  Ok lar... Joking wif u oni...                                                                                                                                 \n",
            "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
            "3  U dun say so early hor... U c already then say...                                                                                                             \n",
            "4  Nah I don't think he goes to usf, he lives around here though                                                                                                 \n",
            "\n",
            "   label_enc  \n",
            "0  0          \n",
            "1  0          \n",
            "2  1          \n",
            "3  0          \n",
            "4  0          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=df['label'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1OO-d77FIwhN",
        "outputId": "4648d788-cbf8-46fe-cc56-e1f3408fcd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'serif' not found because none of the following families were found: Ubuntu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens in all sentences\n",
        "avg_words_len=round(sum([len(i.split()) for i in df['Text']])/len(df['Text']))\n",
        "print(avg_words_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ6FeU-oI3aB",
        "outputId": "942a28b8-de3a-4e25-ec35-43e0e525bbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding Total no of unique words in corpus\n",
        "s = set()\n",
        "for sent in df['Text']:\n",
        "  for word in sent.split():\n",
        "    s.add(word)\n",
        "total_words_length=len(s)\n",
        "print(total_words_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDsZqDyQI7aA",
        "outputId": "576d2f91-a8be-4523-aa3d-b2ab6d636ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data for Training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = np.asanyarray(df['Text']), np.asanyarray(df['label_enc'])\n",
        "new_df = pd.DataFrame({'Text': X, 'label': y})\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    new_df['Text'], new_df['label'], test_size=0.2, random_state=42)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFFJ0v8yI_pl",
        "outputId": "50c00371-1505-4c0a-8dad-e11f27cb627e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4457,), (4457,), (1115,), (1115,))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "tfidf_vec = TfidfVectorizer().fit(X_train)\n",
        "X_train_vec,X_test_vec = tfidf_vec.transform(X_train),tfidf_vec.transform(X_test)\n",
        "\n",
        "baseline_model = MultinomialNB()\n",
        "baseline_model.fit(X_train_vec,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Ocm6k1cvJE2X",
        "outputId": "c246b2aa-c802-499f-9475-235337c5fb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True, force_alpha='warn')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True, force_alpha=&#x27;warn&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True, force_alpha=&#x27;warn&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "MAXTOKENS=total_words_length\n",
        "OUTPUTLEN=avg_words_len\n",
        "\n",
        "text_vec = TextVectorization(\n",
        "    max_tokens=MAXTOKENS,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    output_mode='int',\n",
        "    output_sequence_length=OUTPUTLEN\n",
        ")\n",
        "text_vec.adapt(X_train)"
      ],
      "metadata": {
        "id": "VO35ZB-vJLf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    input_dim=MAXTOKENS,\n",
        "    output_dim=128,\n",
        "    embeddings_initializer='uniform',\n",
        "    input_length=OUTPUTLEN\n",
        ")"
      ],
      "metadata": {
        "id": "aNfrkCSfJTkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
        "vec_layer = text_vec(input_layer)\n",
        "embedding_layer_model = embedding_layer(vec_layer)\n",
        "x = layers.GlobalAveragePooling1D()(embedding_layer_model)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_1 = keras.Model(input_layer, output_layer)\n",
        "\n",
        "model_1.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(\n",
        "    label_smoothing=0.5), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GgL4F3qWJZ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def compile_model(model):\n",
        "    '''\n",
        "    simply compile the model with adam optimzer\n",
        "    '''\n",
        "    model.compile(optimizer=keras.optimizers.Adam(),\n",
        "                  loss=keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "def fit_model(model, epochs, X_train=X_train, y_train=y_train,\n",
        "              X_test=X_test, y_test=y_test):\n",
        "    '''\n",
        "    fit the model with given epochs, train\n",
        "    and test data\n",
        "    '''\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        validation_steps=int(0.2*len(X_test)))\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    '''\n",
        "    evaluate the model and returns accuracy,\n",
        "    precision, recall and f1-score\n",
        "    '''\n",
        "    y_preds = np.round(model.predict(X))\n",
        "    accuracy = accuracy_score(y, y_preds)\n",
        "    precision = precision_score(y, y_preds)\n",
        "    recall = recall_score(y, y_preds)\n",
        "    f1 = f1_score(y, y_preds)\n",
        "\n",
        "    model_results_dict = {'accuracy': accuracy,\n",
        "                          'precision': precision,\n",
        "                          'recall': recall,\n",
        "                          'f1-score': f1}\n",
        "\n",
        "    return model_results_dict"
      ],
      "metadata": {
        "id": "nu-KvDjtJiz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
        "vec_layer = text_vec(input_layer)\n",
        "embedding_layer_model = embedding_layer(vec_layer)\n",
        "bi_lstm = layers.Bidirectional(layers.LSTM(\n",
        "    64, activation='tanh', return_sequences=True))(embedding_layer_model)\n",
        "lstm = layers.Bidirectional(layers.LSTM(64))(bi_lstm)\n",
        "flatten = layers.Flatten()(lstm)\n",
        "dropout = layers.Dropout(.1)(flatten)\n",
        "x = layers.Dense(32, activation='relu')(dropout)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = keras.Model(input_layer, output_layer)\n",
        "\n",
        "compile_model(model_2)  # compile the model\n",
        "history_2 = fit_model(model_2, epochs=5)  # fit the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeHfCUzfJnku",
        "outputId": "c6090b2c-5612-4397-9193-3cb841f301a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 38s 199ms/step - loss: 0.1722 - accuracy: 0.9381 - val_loss: 0.0819 - val_accuracy: 0.9749\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 13s 92ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 0.0832 - val_accuracy: 0.9767\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 13s 96ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1051 - val_accuracy: 0.9785\n",
            "Epoch 4/5\n",
            "140/140 [==============================] - 18s 126ms/step - loss: 3.7807e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9794\n",
            "Epoch 5/5\n",
            "140/140 [==============================] - 12s 89ms/step - loss: 5.4840e-05 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# model with Sequential api\n",
        "model_3 = keras.Sequential()\n",
        "\n",
        "# universal-sentence-encoder layer\n",
        "# directly from tfhub\n",
        "use_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "\t\t\t\t\t\ttrainable=False,\n",
        "\t\t\t\t\t\tinput_shape=[],\n",
        "\t\t\t\t\t\tdtype=tf.string,\n",
        "\t\t\t\t\t\tname='USE')\n",
        "model_3.add(use_layer)\n",
        "model_3.add(layers.Dropout(0.2))\n",
        "model_3.add(layers.Dense(64, activation=keras.activations.relu))\n",
        "model_3.add(layers.Dense(1, activation=keras.activations.sigmoid))\n",
        "\n",
        "compile_model(model_3)\n",
        "\n",
        "history_3 = fit_model(model_3, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObuHHw7SJrZx",
        "outputId": "1bf1506c-c153-4e91-b983-db05a9f7eff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 6s 26ms/step - loss: 0.2861 - accuracy: 0.9186 - val_loss: 0.1116 - val_accuracy: 0.9695\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 3s 24ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0707 - val_accuracy: 0.9767\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 4s 28ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.0569 - val_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "140/140 [==============================] - 5s 32ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0513 - val_accuracy: 0.9830\n",
            "Epoch 5/5\n",
            "140/140 [==============================] - 3s 21ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0507 - val_accuracy: 0.9830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_results = evaluate_model(baseline_model, X_test_vec, y_test)\n",
        "model_1_results = evaluate_model(model_1, X_test, y_test)\n",
        "model_2_results = evaluate_model(model_2, X_test, y_test)\n",
        "model_3_results = evaluate_model(model_3, X_test, y_test)\n",
        "\n",
        "total_results = pd.DataFrame({'MultinomialNB Model':baseline_model_results,\n",
        "                             'Custom-Vec-Embedding Model':model_1_results,\n",
        "                             'Bidirectional-LSTM Model':model_2_results,\n",
        "                             'USE-Transfer learning Model':model_3_results}).transpose()\n",
        "\n",
        "print(total_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a38AQupKwPJ",
        "outputId": "2e28c13b-49eb-4479-a93a-dcb7cf07d3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 5ms/step\n",
            "35/35 [==============================] - 1s 27ms/step\n",
            "35/35 [==============================] - 1s 24ms/step\n",
            "                             accuracy  precision    recall  f1-score\n",
            "MultinomialNB Model          0.962332  1.000000   0.720000  0.837209\n",
            "Custom-Vec-Embedding Model   0.238565  0.101482   0.593333  0.173320\n",
            "Bidirectional-LSTM Model     0.978475  0.943662   0.893333  0.917808\n",
            "USE-Transfer learning Model  0.982960  0.958042   0.913333  0.935154\n"
          ]
        }
      ]
    }
  ]
}